# v6_sftp_to_blob_with_controlmaster.py
### This version builds on V5 and also inserts clientid metadata into the control_master SQL table, with duplicate prevention.

import os
import paramiko
import pandas as pd
import pyodbc
import hashlib
from io import BytesIO
from dotenv import load_dotenv
from azure.storage.blob import BlobServiceClient
from datetime import datetime
import pytz

# Load environment variables
load_dotenv()

# Azure Blob Storage config
AZURE_STORAGE_ACCOUNT = os.getenv("AZURE_STORAGE_ACCOUNT")
AZURE_STORAGE_KEY = os.getenv("AZURE_STORAGE_KEY")
RAW_CONTAINER = os.getenv("AZURE_RAW_CONTAINER")
TRANSFORMED_CONTAINER = os.getenv("AZURE_TRANSFORMED_CONTAINER")

# Client config
CLIENTS = {
    "clientA": {"user": os.getenv("SFTP_CLIENTA_USER"), "pass": os.getenv("SFTP_CLIENTA_PASS"), "id": 12659},
    "clientB": {"user": os.getenv("SFTP_CLIENTB_USER"), "pass": os.getenv("SFTP_CLIENTB_PASS"), "id": 12660},
}

# Initialize Azure Blob client
blob_service_client = BlobServiceClient(account_url=f"https://{AZURE_STORAGE_ACCOUNT}.blob.core.windows.net", credential=AZURE_STORAGE_KEY)
raw_container_client = blob_service_client.get_container_client(RAW_CONTAINER)
transformed_container_client = blob_service_client.get_container_client(TRANSFORMED_CONTAINER)

CONTROLNO_START = 1000

# Wrapper 1: Adds controlno and clientid as the first two columns in the DataFrame
def add_controlno_and_clientid(df, controlno, clientid):
    df.insert(0, 'controlno', controlno)
    df.insert(1, 'clientid', clientid)
    return df

# Wrapper 2: Uploads raw or transformed file data to the correct Azure Blob container
def upload_to_blob(file_data, blob_name, is_transformed=False):
    blob_client = (transformed_container_client if is_transformed else raw_container_client).get_blob_client(blob_name)
    if not blob_client.exists():
        blob_client.upload_blob(file_data, overwrite=True)
        print(f"‚úÖ Uploaded {'transformed' if is_transformed else 'raw'}: {blob_name}")
    else:
        print(f"‚ö†Ô∏è Skipped duplicate blob: {blob_name}")

# Wrapper 3: Inserts metadata into the control_master SQL table with duplicate prevention
def insert_into_control_master(clientid, filename, recordcount, file_bytes):
    try:
        file_hash = hashlib.sha256(file_bytes).hexdigest()
        est = pytz.timezone('US/Eastern')
        load_timestamp = datetime.now(est).strftime('%Y-%m-%d %H:%M:%S')

        conn = pyodbc.connect(
            f"DRIVER={os.getenv('SQL_DRIVER')};"
            f"SERVER={os.getenv('SQL_SERVER')};"
            f"DATABASE={os.getenv('SQL_DATABASE')};"
            f"UID={os.getenv('SQL_USERNAME')};"
            f"PWD={os.getenv('SQL_PASSWORD')}"
        )
        cursor = conn.cursor()

        # Check for duplicates by FileName + ClientID
        cursor.execute("SELECT 1 FROM control_master WHERE FileName = ? AND ClientID = ?", (filename, clientid))
        if cursor.fetchone():
            print(f"‚ö†Ô∏è Entry for {filename} and ClientID {clientid} already exists in control_master. Skipping insert.")
            conn.close()
            return

        # Insert record without controlno (auto-generated by SQL)
        cursor.execute("""
            INSERT INTO control_master (ClientID, FileName, RecordCount, LoadTimestamp, SourceSystem, FileHash)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (
            clientid,
            filename,
            recordcount,
            load_timestamp,
            "pipeline transfer",
            file_hash
        ))

        conn.commit()
        cursor.close()
        conn.close()
        print(f"‚úÖ Inserted control_master record for {filename}")

    except Exception as e:
        print(f"‚ùå Failed to insert into control_master: {e}")

# Wrapper 4: Downloads a file from SFTP, transforms it, uploads it, and logs to SQL
def process_file(sftp, client_name, file_name, controlno):
    remote_path = f"/upload/{file_name}"
    file_data = BytesIO()
    sftp.getfo(remote_path, file_data)
    file_data.seek(0)

    df = pd.read_csv(file_data)
    df = add_controlno_and_clientid(df, controlno, CLIENTS[client_name]['id'])

    # Insert control record to control_master table
    recordcount = len(df)
    file_data.seek(0)
    insert_into_control_master(
        clientid=CLIENTS[client_name]['id'],
        filename=file_name,
        recordcount=recordcount,
        file_bytes=file_data.read()
    )

    # Reset again for blob upload
    file_data.seek(0)
    output_buffer = BytesIO()
    df.to_csv(output_buffer, index=False)
    output_buffer.seek(0)

    transformed_name = f"{client_name.lower()}_transformed_{file_name}"
    upload_to_blob(output_buffer, transformed_name, is_transformed=True)

    file_data.seek(0)
    raw_name = f"{client_name.lower()}_{file_name}"
    upload_to_blob(file_data, raw_name, is_transformed=False)

    return controlno + 1

# Wrapper 5: Connects to each client's SFTP, processes new files, and skips previously processed ones
def handle_client(client_name, controlno):
    print(f"\nüîÑ Connecting to {client_name}...")
    transport = paramiko.Transport((os.getenv("SFTP_HOST"), int(os.getenv("SFTP_PORT"))))
    transport.connect(username=CLIENTS[client_name]['user'], password=CLIENTS[client_name]['pass'])
    sftp = paramiko.SFTPClient.from_transport(transport)

    try:
        files = sftp.listdir("/upload")
        for file_name in files:
            if file_name.startswith("transformed"):
                continue
            blob_name = f"{client_name.lower()}_{file_name}"
            if not raw_container_client.get_blob_client(blob_name).exists():
                controlno = process_file(sftp, client_name, file_name, controlno)
            else:
                print(f"üîÅ Already processed: {blob_name}")
    finally:
        sftp.close()
        transport.close()

    return controlno

# Wrapper 6: Main entry point that iterates through all clients and processes their files
def main():
    controlno = CONTROLNO_START
    for client_name in CLIENTS:
        controlno = handle_client(client_name, controlno)
    print("\n‚úÖ All client files processed.")

if __name__ == "__main__":
    main()
